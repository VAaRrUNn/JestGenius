{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers accelerate gradio kaggle -q\n!pip install -U transformers -q\n!pip install -U datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-07T11:01:22.123146Z","iopub.execute_input":"2024-01-07T11:01:22.123527Z","iopub.status.idle":"2024-01-07T11:02:28.862869Z","shell.execute_reply.started":"2024-01-07T11:01:22.123495Z","shell.execute_reply":"2024-01-07T11:02:28.861795Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\njupyterlab 4.0.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.1 requires jupyterlab<5.0.0a0,>=4.0.6, but you have jupyterlab 4.0.5 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.24.3 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.4 which is incompatible.\ntensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.9.0 which is incompatible.\ntensorflow-probability 0.21.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\ntensorflowjs 4.14.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\nydata-profiling 4.5.1 requires pydantic<2,>=1.8.1, but you have pydantic 2.5.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nCollecting datasets\n  Obtaining dependency information for datasets from https://files.pythonhosted.org/packages/ec/93/454ada0d1b289a0f4a86ac88dbdeab54921becabac45da3da787d136628f/datasets-2.16.1-py3-none-any.whl.metadata\n  Downloading datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.12.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.24.3)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nCollecting pyarrow-hotfix (from datasets)\n  Obtaining dependency information for pyarrow-hotfix from https://files.pythonhosted.org/packages/e4/f4/9ec2222f5f5f8ea04f66f184caafd991a39c8782e31f5b0266f101cb68ca/pyarrow_hotfix-0.6-py3-none-any.whl.metadata\n  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nCollecting fsspec[http]<=2023.10.0,>=2023.1.0 (from datasets)\n  Obtaining dependency information for fsspec[http]<=2023.10.0,>=2023.1.0 from https://files.pythonhosted.org/packages/e8/f6/3eccfb530aac90ad1301c582da228e4763f19e719ac8200752a4841b0b2d/fsspec-2023.10.0-py3-none-any.whl.metadata\n  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.5)\nRequirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.19.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.7.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nDownloading datasets-2.16.1-py3-none-any.whl (507 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\nDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pyarrow-hotfix, fsspec, datasets\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2023.12.2\n    Uninstalling fsspec-2023.12.2:\n      Successfully uninstalled fsspec-2023.12.2\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\ndask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ngcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.10.0 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\nraft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ns3fs 2023.12.2 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-2.16.1 fsspec-2023.10.0 pyarrow-hotfix-0.6\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel\nimport numpy as np\n\nimport logging\nlogging.getLogger().setLevel(logging.CRITICAL)\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2024-01-07T11:02:28.864807Z","iopub.execute_input":"2024-01-07T11:02:28.865159Z","iopub.status.idle":"2024-01-07T11:02:33.867919Z","shell.execute_reply.started":"2024-01-07T11:02:28.865128Z","shell.execute_reply":"2024-01-07T11:02:33.867032Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\nmodel = GPT2LMHeadModel.from_pretrained('gpt2')","metadata":{"execution":{"iopub.status.busy":"2024-01-07T11:02:33.869093Z","iopub.execute_input":"2024-01-07T11:02:33.869612Z","iopub.status.idle":"2024-01-07T11:02:42.303066Z","shell.execute_reply.started":"2024-01-07T11:02:33.869578Z","shell.execute_reply":"2024-01-07T11:02:42.302086Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"616f8160d0be406ea3b04da59be9bc9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7225ae821eb415cbb84ec98ab771040"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8ce515ea447455ea259635cf0a9ce27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6acacc89fe54818a359eb6dec33009c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cc8f4c6232a44c3a62b8ab6ba4b2318"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09501ea662404b5fb0206c5cb5979f03"}},"metadata":{}}]},{"cell_type":"code","source":"# Add the EOS token as the padding token\ntokenizer.pad_token = tokenizer.eos_token\nprint(tokenizer.special_tokens_map)","metadata":{"execution":{"iopub.status.busy":"2024-01-07T11:02:42.305125Z","iopub.execute_input":"2024-01-07T11:02:42.305530Z","iopub.status.idle":"2024-01-07T11:02:42.310739Z","shell.execute_reply.started":"2024-01-07T11:02:42.305500Z","shell.execute_reply":"2024-01-07T11:02:42.309858Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"{'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}\n","output_type":"stream"}]},{"cell_type":"code","source":"hub_model_name = \"JokesGPT\"\nmodel.push_to_hub(hub_model_name, use_auth_token=\"enter_your_token_here\")\ntokenizer.push_to_hub(hub_model_name, use_auth_token=\"enter_your_token_here\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"Amirkid/jokes\")","metadata":{"execution":{"iopub.status.busy":"2024-01-07T11:14:53.936414Z","iopub.execute_input":"2024-01-07T11:14:53.937342Z","iopub.status.idle":"2024-01-07T11:15:36.124052Z","shell.execute_reply.started":"2024-01-07T11:14:53.937307Z","shell.execute_reply":"2024-01-07T11:15:36.123198Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/226 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de2d6d5a9e4343559c1c06697359e8ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/86.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d39c699f57f4d3da84d16db90eeab22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/578634 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92fbb84ec86749e79383530c24ca342c"}},"metadata":{}}]},{"cell_type":"code","source":"def preprocess(ex):\n    ex[\"text\"] = [\"JOKE: \" + x for x in ex[\"text\"] if x]\n    ex = tokenizer(ex[\"text\"], truncation=True)\n    return ex\ntokenized_dataset = dataset.map(preprocess, batched=True, batch_size = 2000, num_proc=8, remove_columns=dataset[\"train\"].features)","metadata":{"execution":{"iopub.status.busy":"2024-01-07T11:15:36.125582Z","iopub.execute_input":"2024-01-07T11:15:36.126040Z","iopub.status.idle":"2024-01-07T11:17:43.349484Z","shell.execute_reply.started":"2024-01-07T11:15:36.126011Z","shell.execute_reply":"2024-01-07T11:17:43.348408Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=8):   0%|          | 0/578634 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3be29a76a41043398337e244d75f9fc2"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\ndata_collator = DataCollatorWithPadding(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-01-07T11:17:43.351137Z","iopub.execute_input":"2024-01-07T11:17:43.351505Z","iopub.status.idle":"2024-01-07T11:17:53.299106Z","shell.execute_reply.started":"2024-01-07T11:17:43.351468Z","shell.execute_reply":"2024-01-07T11:17:53.298111Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loader = DataLoader(tokenized_dataset[\"train\"], collate_fn = data_collator, batch_size = 8)\n# for a in loader:\n#     print(a[\"input_ids\"])\n#     break","metadata":{"execution":{"iopub.status.busy":"2024-01-07T10:56:51.112721Z","iopub.execute_input":"2024-01-07T10:56:51.113699Z","iopub.status.idle":"2024-01-07T10:56:51.117897Z","shell.execute_reply.started":"2024-01-07T10:56:51.113662Z","shell.execute_reply":"2024-01-07T10:56:51.117022Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom tqdm import tqdm\nEPOCHS = 1\nBATCH_SIZE = 4\nloader = DataLoader(tokenized_dataset[\"train\"], collate_fn = data_collator, batch_size = BATCH_SIZE)\ndataset_size = tokenized_dataset[\"train\"].num_rows \nnum_batches = dataset_size/BATCH_SIZE\nnum_training_steps = EPOCHS * num_batches\n\nprogress_bar = tqdm(total = num_training_steps)\n\nlr = 5e-5\noptimizer = torch.optim.AdamW(model.parameters(), lr = lr)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nlosses = []\nmodel.to(device)\nmodel.train()\n\nactual_idx = 0\nfor a in loader:\n    if actual_idx % 100 == 0 and actual_idx != 0:\n        print(f\"saving model for iteration: {actual_idx}\")\n        print(f\"Loss: {sum(losses)/len(losses)}\")\n        print(f\"-----------------------\")\n        model.push_to_hub(hub_model_name, commit_message = f\"iteration {actual_idx}\", use_auth_token=\"enter_your_token_here\")\n        \n    if actual_idx % 100 == 0 and actual_idx != 0:\n        print(f\"Loss: {sum(losses)/len(losses)}\")\n    \n    actual_idx += 1\n    input_ids, attention_mask = a[\"input_ids\"], a[\"attention_mask\"]\n    input_ids, attention_mask = input_ids.type(torch.long).to(device), attention_mask.type(torch.long).to(device)\n    out = model(input_ids = input_ids,\n                attention_mask=attention_mask,\n               labels = input_ids)\n    \n    loss, logits = out[:2]\n    \n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    losses.append(loss.item())\n\n#     progress_bar.update(1)","metadata":{"execution":{"iopub.status.busy":"2024-01-07T11:17:53.301083Z","iopub.execute_input":"2024-01-07T11:17:53.301683Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"  0%|          | 0/143539.75 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"saving model for iteration: 100\nLoss: 2.09256292283535\n-----------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48adcc0410274431b92569f81e7afd23"}},"metadata":{}},{"name":"stdout","text":"Loss: 2.09256292283535\nsaving model for iteration: 200\nLoss: 2.0388212782144546\n-----------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d022cb7d673407bb6e61a3eb1127e9f"}},"metadata":{}},{"name":"stdout","text":"Loss: 2.0388212782144546\nsaving model for iteration: 300\nLoss: 2.003195122083028\n-----------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34cef540d07144c380ab455ec9aa8902"}},"metadata":{}},{"name":"stdout","text":"Loss: 2.003195122083028\nsaving model for iteration: 400\nLoss: 1.9579844583570958\n-----------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da5c90b3bbae4d76913110242da0295d"}},"metadata":{}},{"name":"stdout","text":"Loss: 1.9579844583570958\nsaving model for iteration: 500\nLoss: 1.9649591513872147\n-----------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff93936574234a9c95467c6189a05ebe"}},"metadata":{}},{"name":"stdout","text":"Loss: 1.9649591513872147\nsaving model for iteration: 600\nLoss: 1.949827377796173\n-----------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"875a9c1ad35f49c88951295b0e07c2fc"}},"metadata":{}},{"name":"stdout","text":"Loss: 1.949827377796173\nsaving model for iteration: 700\nLoss: 1.9422637623548509\n-----------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d98e599c1b60447c9d7c5b8e5518ae8c"}},"metadata":{}},{"name":"stdout","text":"Loss: 1.9422637623548509\nsaving model for iteration: 800\nLoss: 1.9527688504755496\n-----------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4f0cfe5fd474621b8b3e8771a5f2efd"}},"metadata":{}},{"name":"stdout","text":"Loss: 1.9527688504755496\nsaving model for iteration: 900\nLoss: 1.9471107096225024\n-----------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f4e8f1ce4a842ba9ae4b0a8d266be6b"}},"metadata":{}},{"name":"stdout","text":"Loss: 1.9471107096225024\nsaving model for iteration: 1000\nLoss: 1.9507824485972525\n-----------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb802f414e52475ca1d612658a1a45c1"}},"metadata":{}},{"name":"stdout","text":"Loss: 1.9507824485972525\nsaving model for iteration: 1100\nLoss: 1.9620680415698073\n-----------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf22317d255b44e1a8e61973a85d1029"}},"metadata":{}},{"name":"stdout","text":"Loss: 1.9620680415698073\nsaving model for iteration: 1200\nLoss: 1.9679153614801665\n-----------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fb102b489ff4d7b9d62c1721b5bce07"}},"metadata":{}},{"name":"stdout","text":"Loss: 1.9679153614801665\nsaving model for iteration: 1300\nLoss: 1.9738611203489396\n-----------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e60439e6d77495f8ec91fdc2e07dbd7"}},"metadata":{}},{"name":"stdout","text":"Loss: 1.9738611203489396\nsaving model for iteration: 1400\nLoss: 1.970009876526892\n-----------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63f79eeabc3346d2b076c896a7198c92"}},"metadata":{}},{"name":"stdout","text":"Loss: 1.970009876526892\nsaving model for iteration: 1500\nLoss: 1.9627266168743371\n-----------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"398bd07c6dd84297bb2594b1a68c8feb"}},"metadata":{}},{"name":"stdout","text":"Loss: 1.9627266168743371\nsaving model for iteration: 1600\nLoss: 1.9551352923503145\n-----------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55ce3014464f4fbdb3f911dabac71bcd"}},"metadata":{}}]}]}